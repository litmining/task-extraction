[{"33604196": {"pmcid": "33604196", "task": {"id": "trm_4da890594742a", "name": "emotional regulation task", "definition_text": "participant completes task that induces emotional conflict while behavioral and/or physiological data is collected"}, "pmid": "33604196", "doi": "10.1503/jpn.130080"}}, {"24690369": {"pmcid": "24690369", "task": {"id": "trm_4da890594742a", "name": "emotional regulation task", "definition_text": "participant completes task that induces emotional conflict while behavioral and/or physiological data is collected"}, "pmid": "24690369", "doi": "10.1503/jpn.130080"}}, {"37028931": {"pmcid": "37028931", "task": {"id": "tsk_29IL64WzhiO9u", "name": "Self evaluation task", "definition_text": "A task in which participants evaluate how well several short trait descriptions fit the self."}, "pmid": "37028931", "doi": "10.1523/JNEUROSCI.2178-22.2023"}}, {"35348787": {"pmcid": "35348787", "task": {"id": "trm_59668f09db813", "name": "Yellow Light Game", "definition_text": "The Yellow Light Game (YLG) is a computerized driving simulation task that was modified from the Stoplight Task (Gardner & Steinberg, 2005; Chein et al., 2011). Similar to the Stoplight Task, each run in the YLG involves participants driving on a straight road with 20 intersections, each controlled by a traffic light. Participants are instructed that the goal of the game is to get the fastest time. At each intersection, when the traffic light turns yellow, participants choose to either continue through the intersection (Go decision), or to stop the car (Stop decision); they are not able to accelerate or steer. Participants are instructed that Go decisions would result in the fastest time, unless another car is present on the cross street, in which case the participant would crash. Crashes double the time spent at an intersection compared to if the participant had decided to stop. Therefore, Go decisions are considered \u00e2\u0080\u0098risky\u00e2\u0080\u0099, whereas Stop decisions are considered \u00e2\u0080\u0098safe\u00e2\u0080\u0099. Upon completion of a run, participants are presented with their completion time and the number of crashes during that run.\r\n\r\nA unique feature of the YLG is that there are three different types of intersections, which vary based on the timing of yellow light onset and the presence or absence of a car on the cross street. Some intersections have a 75% probability of crashing, others have a 25% probability of crashing, and the remaining intersections have a 50% probability of crashing. To prevent the task from promoting risk taking overall, the cumulative probability of crashing is set to 50% (i.e., 10 out of the 20 intersections have cars approaching on the cross street, resulting in a crash if the participant made a Go decision). This task feature is not explicitly communicated to participants, although participants have the opportunity to implicitly learn this information based on the differential timing of the yellow light onsets associated with each type of intersection. That is, intersections at which the light turns yellow earlier (i.e., when the participant was further away from the intersection) signal a greater crash probability. By including the different types of intersections, we are able to distinguish between adaptive and maladaptive risk taking, without promoting risk taking overall, as the cumulative probability of crashing is 50%. For more information about and access to the task, please visit: https://dsn.uoregon.edu/research/yellow-light-game/. "}, "pmid": "35348787", "doi": "10.1093/scan/nsac025"}}, {"37154430": {"pmcid": "37154430", "task": {"id": "tsk_29IL64WzhiO9u", "name": "Self evaluation task", "definition_text": "A task in which participants evaluate how well several short trait descriptions fit the self."}, "pmid": "37154430", "doi": "10.1093/scan/nsad016"}}, {"26512314": {"pmcid": "26512314", "task": {"id": "trm_550b557e5f90e", "name": "social cognition (theory of mind) fMRI task paradigm", "definition_text": "Participants were presented with short video clips (20 seconds) of objects (squares, circles, triangles) that either interacted in some way, or moved randomly on the screen. These videos were developed by either Castelli and colleagues (Castelli et al. 2000) or Martin and colleagues (Wheatley et al. 2007). After each video clip, participants judge whether the objects had a mental interaction (an interaction that appears as if the shapes are taking into account each other\u00e2\u0080\u0099s feelings and thoughts), Not Sure, or No interaction (i.e., there is no obvious interaction between the shapes and the movement appears random). Each of the two task runs has 5 video blocks (2 Mental and 3 Random in one run, 3 Mental and 2 Random in the other run) and 5 fixation blocks (15 seconds each). \r\n\r\nReferences for the Social Cognition Task: Reliable across subjects and robust activation\r\n(Castelli et al. 2000; Castelli et al. 2002; Wheatley et al. 2007; White et al. 2011).\r\n\r\nThis task is used in the Human Connectome Project.\r\n\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Reference_Manual.pdf"}, "pmid": "26512314", "doi": "10.1186/s13229-015-0052-x"}}, {"33240117": {"pmcid": "33240117", "task": {"id": "trm_550b557e5f90e", "name": "social cognition (theory of mind) fMRI task paradigm", "definition_text": "Participants were presented with short video clips (20 seconds) of objects (squares, circles, triangles) that either interacted in some way, or moved randomly on the screen. These videos were developed by either Castelli and colleagues (Castelli et al. 2000) or Martin and colleagues (Wheatley et al. 2007). After each video clip, participants judge whether the objects had a mental interaction (an interaction that appears as if the shapes are taking into account each other\u00e2\u0080\u0099s feelings and thoughts), Not Sure, or No interaction (i.e., there is no obvious interaction between the shapes and the movement appears random). Each of the two task runs has 5 video blocks (2 Mental and 3 Random in one run, 3 Mental and 2 Random in the other run) and 5 fixation blocks (15 seconds each). \r\n\r\nReferences for the Social Cognition Task: Reliable across subjects and robust activation\r\n(Castelli et al. 2000; Castelli et al. 2002; Wheatley et al. 2007; White et al. 2011).\r\n\r\nThis task is used in the Human Connectome Project.\r\n\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Reference_Manual.pdf"}, "pmid": "33240117", "doi": "10.3389/fpsyt.2020.544482"}}, {"34075542": {"pmcid": "34075542", "task": {"id": "trm_4d55a2bbcfdff", "name": "choice task between risky and non-risky options", "definition_text": "a choice made between two or more options when one of those options has some probability >0 of producing either a reinforcing or an aversive consequence"}, "pmid": "34075542", "doi": "10.3758/s13415-021-00913-w"}}, {"31191278": {"pmcid": "31191278", "task": {"id": "trm_4d559bcd67c18", "name": "balloon analogue risk task", "definition_text": "On each trial, participants pump a simulated balloon without knowing when it will explode. Each pump increases the potential reward to be gained but also the probability of explosion, which wipes out all potential gains for that trial. In most studies, balloon explosion probabilities are drawn from a uniform distribution, and participants must learn explosion probabilities through trial-and-error."}, "pmid": "31191278", "doi": "10.3389/fnhum.2019.00171"}}, {"32792423": {"pmcid": "32792423", "task": {"id": "trm_4c8a834779883", "name": "rest eyes open", "definition_text": "Subjects rest passively with their eyes open. Often used as a baseline for comparison for other tasks."}, "pmid": "32792423", "doi": "10.1136/bmjopen-2019-034110"}}, {"24920856": {"pmcid": "24920856", "task": {"id": "trm_4c8a834779883", "name": "rest eyes open", "definition_text": "Subjects rest passively with their eyes open. Often used as a baseline for comparison for other tasks."}, "pmid": "24920856", "doi": "10.1212/WNL.0000000000000592"}}, {"36617994": {"pmcid": "36617994", "task": {"id": "trm_5550e5011ce10", "name": "audio narrative", "definition_text": "Audio narratives tell stories through sound alone: narration, interviews, live and archival sound recordings, environmental soundscapes, sound effects, found sounds, etc. Audio narratives use storytelling along with other audio means to create intimate experiences through characters, plot, and setting."}, "pmid": "36617994", "doi": "10.1002/hbm.26199"}}, {"36440544": {"pmcid": "36440544", "task": {"id": "trm_54e69c642d89b", "name": "rest eyes closed", "definition_text": "Subjects rest passively with their eyes closed. Often used as a baseline for comparison for other tasks."}, "pmid": "36440544", "doi": "10.1002/jnr.25149"}}, {"37090969": {"pmcid": "37090969", "task": {"id": "trm_553ebfc390256", "name": "perceptual discrimination task", "definition_text": "Participants are asked to distinguish a gabor display that is &#34;popping out&#34; from one that is not, and rate their confidence on the decision on a scale of 1 (low confidence) to 6 (high confidence).  Full details are available: http://www.jneurosci.org/content/33/42/16657.full#F1"}, "pmid": "37090969", "doi": "10.1098/rsos.221091"}}, {"35796178": {"pmcid": "35796178", "task": {"id": "trm_5667441c338a7", "name": "2nd-order rule acquisition", "definition_text": "In this task, subjects are presented with 18 stimuli composed of three dimensions: 3 shapes, 3 orientations and 2 colored borders. Subjects had to learn one of three key responses for each of the 18 stimuli. In the &#34;flat&#34; condition, the 18 stimuli to 3 responses mapping was arbitrary, requiring subjects to individually learn each of the 18 associations. In a hierarchical condition, the colored borders indicated whether &#34;orientation&#34; or &#34;shape&#34; determined the response. This simplifies performance if subjects learn this hierarchical structure."}, "pmid": "35796178", "doi": "10.1002/hbm.25999"}}, {"35169702": {"pmcid": "35169702", "task": {"id": "trm_5667441c338a7", "name": "2nd-order rule acquisition", "definition_text": "In this task, subjects are presented with 18 stimuli composed of three dimensions: 3 shapes, 3 orientations and 2 colored borders. Subjects had to learn one of three key responses for each of the 18 stimuli. In the &#34;flat&#34; condition, the 18 stimuli to 3 responses mapping was arbitrary, requiring subjects to individually learn each of the 18 associations. In a hierarchical condition, the colored borders indicated whether &#34;orientation&#34; or &#34;shape&#34; determined the response. This simplifies performance if subjects learn this hierarchical structure."}, "pmid": "35169702", "doi": "10.1093/braincomms/fcab302"}}, {"36044582": {"pmcid": "36044582", "task": {"id": "tsk_4a57abb949aca", "name": "International Affective Picture System", "definition_text": "a database of photographs used in emotion research."}, "pmid": "36044582", "doi": "10.1126/sciadv.abn8616"}}, {"28503664": {"pmcid": "28503664", "task": {"id": "tsk_4a57abb949aca", "name": "International Affective Picture System", "definition_text": "a database of photographs used in emotion research."}, "pmid": "28503664", "doi": "10.12688/wellcomeopenres.10298.2"}}, {"31409029": {"pmcid": "31409029", "task": {"id": "trm_57ebe6583f52d", "name": "Moral Dilemma Task", "definition_text": "Subjects are presented with vignettes describing either moral dilemmas or non-moral (control) situations.  Each vignette is associated with a question requiring a yes/no answer, and the subject responds with a button press."}, "pmid": "31409029", "doi": "10.3390/brainsci9080198"}}, {"28446105": {"pmcid": "28446105", "task": {"id": "trm_57ebe6583f52d", "name": "Moral Dilemma Task", "definition_text": "Subjects are presented with vignettes describing either moral dilemmas or non-moral (control) situations.  Each vignette is associated with a question requiring a yes/no answer, and the subject responds with a button press."}, "pmid": "28446105", "doi": "10.1080/17470919.2017.1324521"}}, {"37132522": {"pmcid": "37132522", "task": {"id": "trm_550b50095d4a3", "name": "working memory fMRI task paradigm", "definition_text": "This is the &#34;working memory&#34; task used in the Human Connectome Project. The category specific representation task and the working memory task are combined into a single task paradigm. Participants were presented with blocks of trials that consisted of pictures of places, tools, faces and body parts (non-mutilated parts of bodies with no \u00e2\u0080\u009cnudity\u00e2\u0080\u009d). Within each run, the 4 different stimulus types were presented in separate blocks. Also, within each run, \u00c2\u00bd of the blocks use a 2-back working memory task and \u00c2\u00bd use a 0-back working memory task (as a working memory comparison). A 2.5 second cue indicates the task type (and target\r\nfor 0-back) at the start of the block. Each of the two runs contains 8 task blocks (10 trials of 2.5 seconds each, for 25 seconds) and 4 fixation blocks (15 seconds). On each trial, the stimulus is presented for 2 seconds, followed by a 500 ms inter-task interval (ITI). \r\n\r\nPotential Additional Event Related Contrasts: Researchers can also use the TAB.txt E-Prime\r\ndata files to generate the following potential event-related contrasts:\r\n\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Appendix_VI.pdf\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Reference_Manual.pdf\r\n\r\nReferences for Working Memory: Localizer (Drobyshevsky et al. 2006); Reliable across subjects (Drobyshevsky et al. 2006) and time (Caceres et al. 2009)."}, "pmid": "37132522", "doi": "10.1093/gigascience/giad029"}}, {"22366334": {"pmcid": "22366334", "task": {"id": "trm_550b50095d4a3", "name": "working memory fMRI task paradigm", "definition_text": "This is the &#34;working memory&#34; task used in the Human Connectome Project. The category specific representation task and the working memory task are combined into a single task paradigm. Participants were presented with blocks of trials that consisted of pictures of places, tools, faces and body parts (non-mutilated parts of bodies with no \u00e2\u0080\u009cnudity\u00e2\u0080\u009d). Within each run, the 4 different stimulus types were presented in separate blocks. Also, within each run, \u00c2\u00bd of the blocks use a 2-back working memory task and \u00c2\u00bd use a 0-back working memory task (as a working memory comparison). A 2.5 second cue indicates the task type (and target\r\nfor 0-back) at the start of the block. Each of the two runs contains 8 task blocks (10 trials of 2.5 seconds each, for 25 seconds) and 4 fixation blocks (15 seconds). On each trial, the stimulus is presented for 2 seconds, followed by a 500 ms inter-task interval (ITI). \r\n\r\nPotential Additional Event Related Contrasts: Researchers can also use the TAB.txt E-Prime\r\ndata files to generate the following potential event-related contrasts:\r\n\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Appendix_VI.pdf\r\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Reference_Manual.pdf\r\n\r\nReferences for Working Memory: Localizer (Drobyshevsky et al. 2006); Reliable across subjects (Drobyshevsky et al. 2006) and time (Caceres et al. 2009)."}, "pmid": "22366334", "doi": "10.1016/j.neuroimage.2012.02.018"}}, {"36914701": {"pmcid": "36914701", "task": {"id": "trm_4c8a8467304e2", "name": "theory of mind task", "definition_text": "Subjects are asked to perform a task involving the understanding of another&#39;s personal beliefs and feelings or forming hypotheses regarding the mental states of others."}, "pmid": "36914701", "doi": "10.1038/s41598-023-31146-1"}}, {"37215485": {"pmcid": "37215485", "task": {"id": "trm_4c8a834779883", "name": "rest eyes open", "definition_text": "Subjects rest passively with their eyes open. Often used as a baseline for comparison for other tasks."}, "pmid": "37215485", "doi": "10.1093/braincomms/fcad105"}}, {"36958619": {"pmcid": "36958619", "task": {"id": "trm_4c898da401420", "name": "film viewing", "definition_text": "Subjects view movie or film clips passively or are required to make a discrimination when the clip is over."}, "pmid": "36958619", "doi": "10.1016/j.neuroimage.2023.120025"}}, {"35625035": {"pmcid": "35625035", "task": {"id": "trm_5550e5011ce10", "name": "audio narrative", "definition_text": "Audio narratives tell stories through sound alone: narration, interviews, live and archival sound recordings, environmental soundscapes, sound effects, found sounds, etc. Audio narratives use storytelling along with other audio means to create intimate experiences through characters, plot, and setting."}, "pmid": "35625035", "doi": "10.3390/brainsci12050649"}}]